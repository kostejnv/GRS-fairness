{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Group Generation\n",
    "\n",
    "This notebook generate synthetic group based on similiraty/disimilarity of embeddings of users. The similar, divergent and opossing (2 opposite subgroups) groups are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "from datasets import EchoNestLoader, LastFm1kLoader, DataLoader\n",
    "from utils import Utils\n",
    "from models import ELSA\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import os\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "device = Utils.set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "Td_QUANTILE = 0.9\n",
    "Ts_QUANTILE = 0.1\n",
    "\n",
    "SIMILAR_GROUPS = [3,5]\n",
    "DIVIDE_GROUPS = [3,5]\n",
    "OPPOSING_GROUPS = [[2,1], [3,2], [4,1]]\n",
    "\n",
    "FINAL_GROUP_COUNT = 75\n",
    "\n",
    "MAX_RECOMMENDATION_OVERLAP = 0.8\n",
    "\n",
    "DATASET = 'LastFM1k' # 'LastFM1k' or 'EchoNest'\n",
    "MODEL_RUN_ID = '32b65a3a9edf4ff4b46e9d8385d93bc4'\n",
    "\n",
    "OUT_DIR = './data/synthetic_groups'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load run, dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load run\n",
    "\n",
    "run = mlflow.get_run(MODEL_RUN_ID)\n",
    "artifact_path = run.info.artifact_uri.replace('file://', '') # type: ignore\n",
    "params = run.data.params\n",
    "\n",
    "assert params['model'] == 'ELSA', 'Model from run is not ELSA -> not supported'\n",
    "assert params['dataset'] == DATASET, 'Dataset from run is not the same as the current dataset -> not supported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "items = int(params['items'])\n",
    "factors = int(params['factors'])\n",
    "\n",
    "model = ELSA(items, factors).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters()) # not used, but needed for loading\n",
    "Utils.load_checkpoint(model, optimizer, f'{artifact_path}/checkpoint.ckpt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "class Config:\n",
    "    val_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "#Load dataset\n",
    "match DATASET:\n",
    "    case 'EchoNest':\n",
    "        dataset_loader = EchoNestLoader()\n",
    "    case 'LastFM1k':\n",
    "        dataset_loader = LastFm1kLoader()\n",
    "    case _:\n",
    "        raise ValueError(f'Dataset {args.dataset} not supported. Check typos.')\n",
    "dataset_loader.prepare(Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute similarity matrix and thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load interactions\n",
    "csr_interactions = dataset_loader.csr_interactions\n",
    "interactions_batches = DataLoader(csr_interactions, batch_size=1024, device=device, shuffle=False)\n",
    "\n",
    "# create user embeddings\n",
    "batches_embeddings = []\n",
    "for batch in tqdm.tqdm(interactions_batches, desc='Creating user embeddings'):\n",
    "    batch_embeddings = model.encode(batch)\n",
    "    batches_embeddings.append(batch_embeddings)\n",
    "user_embeddings = torch.cat(batches_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute similarity matrix\n",
    "normalized_embeddings = F.normalize(user_embeddings, p=2, dim=1)\n",
    "similarity_matrix = torch.matmul(normalized_embeddings, normalized_embeddings.T)\n",
    "similarity_matrix = (similarity_matrix + 1) / 2 # opposite user embeddings are completely opposite, so we normalize to [0,1]\n",
    "\n",
    "print(f'Similarity matrix shape: {similarity_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute thresholds\n",
    "similarity_values = torch.triu(similarity_matrix, diagonal=1).flatten()\n",
    "similarity_values = similarity_values[similarity_values != 0]\n",
    "\n",
    "Td = similarity_values.quantile(Td_QUANTILE)\n",
    "Ts = similarity_values.quantile(Ts_QUANTILE)\n",
    "\n",
    "print(f'Td: {Td}, Ts: {Ts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_user_similar(group_members, user):\n",
    "    if not group_members:\n",
    "        return True\n",
    "    mean_similarity = similarity_matrix[group_members, user].mean()\n",
    "    return mean_similarity >= Td\n",
    "\n",
    "def _similar_group(group_size):\n",
    "    user_count = similarity_matrix.shape[0]\n",
    "    group_members = [random.randint(0, user_count-1)]\n",
    "    rest = list(set(range(user_count)) - set(group_members))\n",
    "    for _ in range(1_000): # it can be blocked in a loop if the group does not exists\n",
    "        user = random.choice(rest)\n",
    "        if is_user_similar(group_members, user):\n",
    "            group_members.append(user)\n",
    "            rest.remove(user)\n",
    "        if len(group_members) >= group_size:\n",
    "            return group_members\n",
    "    raise TimeoutError('Could not find similar group')\n",
    "\n",
    "def similar_group(group_size):\n",
    "    while True:\n",
    "        try:\n",
    "            return _similar_group(group_size)\n",
    "        except TimeoutError:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_user_divergent(group_members, user):\n",
    "    if not group_members:\n",
    "        return True\n",
    "    mean_similarity = similarity_matrix[group_members, user].mean()\n",
    "    return mean_similarity <= Ts\n",
    "\n",
    "def _divergent_group(group_size):\n",
    "    user_count = similarity_matrix.shape[0]\n",
    "    group_members = [random.randint(0, user_count-1)]\n",
    "    rest = list(set(range(user_count)) - set(group_members))\n",
    "    for _ in range(1_000): # it can be blocked in a loop if the group does not exists\n",
    "        user = random.choice(rest)\n",
    "        if is_user_divergent(group_members, user):\n",
    "            group_members.append(user)\n",
    "            rest.remove(user)\n",
    "        if len(group_members) >= group_size:\n",
    "            return group_members\n",
    "    raise TimeoutError('Could not find divergent group')\n",
    "\n",
    "def divergent_group(group_size):\n",
    "    while True:\n",
    "        try:\n",
    "            return _divergent_group(group_size)\n",
    "        except TimeoutError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def _opposing_group(group_size):\n",
    "    user_count = similarity_matrix.shape[0]\n",
    "    groups_lefts = deepcopy(group_size)\n",
    "    \n",
    "    # choose the first user\n",
    "    group_members = ([random.randint(0, user_count-1)], [])\n",
    "    groups_lefts[0] -= 1\n",
    "    \n",
    "    rest = list(set(range(user_count)) - set(group_members[0]))\n",
    "    \n",
    "    index = 1\n",
    "    for _ in range(1_000):\n",
    "        # choose the subgroup to expand\n",
    "        group_to_expand = index % 2\n",
    "        if groups_lefts[group_to_expand] == 0:\n",
    "            index += 1\n",
    "            group_to_expand = index % 2\n",
    "            \n",
    "        user = random.choice(rest)\n",
    "        if is_user_similar(group_members[group_to_expand], user) and is_user_divergent(group_members[1-group_to_expand], user):\n",
    "            group_members[group_to_expand].append(user)\n",
    "            groups_lefts[group_to_expand] -= 1\n",
    "            rest.remove(user)\n",
    "            \n",
    "        if groups_lefts[0] == 0 and groups_lefts[1] == 0:\n",
    "            return group_members[0] + group_members[1]\n",
    "        index += 1\n",
    "    raise TimeoutError('Could not find opposing group')\n",
    "\n",
    "def opposing_group(group_size):\n",
    "    while True:\n",
    "        try:\n",
    "            return _opposing_group(group_size)\n",
    "        except TimeoutError:\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_similarity(group):\n",
    "    overall_similarity = torch.triu(similarity_matrix[group][:, group], diagonal=1).flatten()\n",
    "    overall_similarity = overall_similarity[overall_similarity != 0].mean()\n",
    "    return overall_similarity.item()\n",
    "\n",
    "def subgroup_similarity(group, subgroup_size):\n",
    "    sub1, sub2 = group[:subgroup_size[0]], group[subgroup_size[0]:]\n",
    "    \n",
    "    sub1_similarity = torch.triu(similarity_matrix[sub1][:, sub1], diagonal=1).flatten()\n",
    "    sub1_similarity = sub1_similarity[sub1_similarity != 0].mean()\n",
    "    \n",
    "    sub2_similarity = torch.triu(similarity_matrix[sub2][:, sub2], diagonal=1).flatten()\n",
    "    sub2_similarity = sub2_similarity[sub2_similarity != 0].mean()\n",
    "    \n",
    "    return sub1_similarity.item(), sub2_similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "similar_groups = {}\n",
    "for group_size in SIMILAR_GROUPS:\n",
    "    similar_groups[group_size] = [similar_group(group_size) for _ in range(FINAL_GROUP_COUNT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "divergent_groups = {}\n",
    "for group_size in DIVIDE_GROUPS:\n",
    "    divergent_groups[group_size] = [divergent_group(group_size) for _ in range(FINAL_GROUP_COUNT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposing_groups = {}\n",
    "for group_size in OPPOSING_GROUPS:\n",
    "    opposing_groups[tuple(group_size)] = [opposing_group(group_size) for _ in range(FINAL_GROUP_COUNT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show histogram for overall similarity for similar groups\n",
    "from plotly import express as px\n",
    "\n",
    "similar_groups_overall_similarity = {group_size: [overall_similarity(group) for group in groups] for group_size, groups in similar_groups.items()}\n",
    "\n",
    "px.histogram(x=similar_groups_overall_similarity[3], nbins=50, title='Overall similarity for similar groups')\n",
    "# px.histogram(x=similar_groups_overall_similarity[5], nbins=50, title='Overall similarity for similar groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergent_groups_overall_similarity = {group_size: [overall_similarity(group) for group in groups] for group_size, groups in divergent_groups.items()}\n",
    "\n",
    "# px.histogram(x=divergent_groups_overall_similarity[3], nbins=50, title='Overall similarity for divergent groups')\n",
    "px.histogram(x=divergent_groups_overall_similarity[5], nbins=50, title='Overall similarity for divergent groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposing_groups_overall_similarity = {group_size: [overall_similarity(group) for group in groups] for group_size, groups in opposing_groups.items()}\n",
    "\n",
    "px.histogram(x=opposing_groups_overall_similarity[(2,1)], nbins=50, title='Overall similarity for opposing groups (2,1)')\n",
    "px.histogram(x=opposing_groups_overall_similarity[(3,2)], nbins=50, title='Overall similarity for opposing groups (3,2)')\n",
    "px.histogram(x=opposing_groups_overall_similarity[(4,1)], nbins=50, title='Overall similarity for opposing groups (4,1)')\n",
    "\n",
    "# subgroup similarity\n",
    "opposing_groups_subgroup_similarity = {group_size: [subgroup_similarity(group, group_size)[1] for group in groups] for group_size, groups in opposing_groups.items()}\n",
    "px.histogram(x=opposing_groups_subgroup_similarity[(3,2)], nbins=50, title='Subgroup similarity for opposing groups (2,1)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_similarity(group1, group2):\n",
    "    '''Return number of common users'''\n",
    "    return len(set(group1) & set(group2)) / len(group1)\n",
    "\n",
    "def show_too_similar_groups(groups, threshold):\n",
    "    index = 0\n",
    "    for i, group1 in enumerate(groups):\n",
    "        for group2 in groups[i+1:]:\n",
    "            similarity = group_similarity(group1, group2)\n",
    "            if similarity >= threshold:\n",
    "                print(f'{index}: Groups {group1} and {group2} are too similar: {similarity}')\n",
    "                index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_too_similar_groups(similar_groups[5], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save groups as numpy arrays\n",
    "\n",
    "out_path = f'{OUT_DIR}/{DATASET}'\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "for group_size, groups in similar_groups.items():\n",
    "    np.save(f'{out_path}/similar_{group_size}.npy', np.array(groups))\n",
    "    \n",
    "for group_size, groups in divergent_groups.items():\n",
    "    np.save(f'{out_path}/divergent_{group_size}.npy', np.array(groups))\n",
    "    \n",
    "for group_size, groups in opposing_groups.items():\n",
    "    np.save(f'{out_path}/opposing_{group_size[0]}_{group_size[1]}.npy', np.array(groups))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
